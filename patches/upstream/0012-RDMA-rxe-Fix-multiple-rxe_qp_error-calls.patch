From: c06083822fd1261a2860ee50e8baedbb981e400c
Author: Bob Pearson <rpearsonhpe@gmail.com>
Date:   Wed Mar 20 09:48:41 2024 -0500

    RDMA/rxe: Fix multiple rxe_qp_error calls

    A older patch attempted to get wr's posted to the send queue to
    be flushed in error when the qp is in the error state by causing
    rxe_requester() to advance it's wqe index in the send queue, move
    the wqe to the error state and then goto the error exit where it
    advances the wqe index *again* and then calls rxe_qp_error(). All
    of this serves no purpose since moving the qp to the error state
    in the first place will also call rxe_completer() which flushes the
    send queue. The effect of this when an upper level app or ulp moves
    the qp to the error state is to have several redundant calls all
    trying to do the same job.

    This patch cleans up this behavior.

    Signed-off-by: Bob Pearson <rpearsonhpe@gmail.com>
    Fixes: ae720bdb703b ("RDMA/rxe: Generate error completion for error requester QP state")

diff --git a/drivers/infiniband/sw/rxe/rxe_req.c b/drivers/infiniband/sw/rxe/rxe_req.c
index d8c41fd626a9..91aa38aa05d8 100644
--- a/drivers/infiniband/sw/rxe/rxe_req.c
+++ b/drivers/infiniband/sw/rxe/rxe_req.c
@@ -684,20 +684,11 @@ int rxe_requester(struct rxe_qp *qp)
	unsigned long flags;

	spin_lock_irqsave(&qp->state_lock, flags);
-	if (unlikely(!qp->valid)) {
+	if (unlikely(!qp->valid || qp_state(qp) == IB_QPS_ERR)) {
		spin_unlock_irqrestore(&qp->state_lock, flags);
		goto exit;
	}

-	if (unlikely(qp_state(qp) == IB_QPS_ERR)) {
-		wqe = __req_next_wqe(qp);
-		spin_unlock_irqrestore(&qp->state_lock, flags);
-		if (wqe)
-			goto err;
-		else
-			goto exit;
-	}
-
	if (unlikely(qp_state(qp) == IB_QPS_RESET)) {
		qp->req.wqe_index = queue_get_consumer(q,
						QUEUE_TYPE_FROM_CLIENT);

