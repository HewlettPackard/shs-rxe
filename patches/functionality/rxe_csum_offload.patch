commit 0cd616042424813de7d7063d109d39e416e5a4a1
Author: Frank <frank.zago@hpe.com>
Date:   Wed Feb 24 12:27:10 2021 -0600

    Add HW support for RoCE checksum
    
    An adapter setting the new NETIF_F_ROCEV2_FULL_CRC feature indicates
    it can do a RoCE checksum on the full packet. In that case, the
    rdma_rxe driver doesn't need to compute any checksum.
    
    On the receive side, the HW will discard bad packets.
    
    On the send side, the HW will compuite the checksum.

diff --git a/roce/rxe/rxe_net.c b/roce/rxe/rxe_net.c
index 312c2fc..b48bd2e 100644
--- a/roce/rxe/rxe_net.c
+++ b/roce/rxe/rxe_net.c
@@ -400,7 +400,8 @@ int rxe_prepare(struct rxe_pkt_info *pkt, struct sk_buff *skb, u32 *crc)
 	else if (skb->protocol == htons(ETH_P_IPV6))
 		err = prepare6(pkt, skb);
 
-	*crc = rxe_icrc_hdr(pkt, skb);
+	if (crc)
+		*crc = rxe_icrc_hdr(pkt, skb);
 
 	if (ether_addr_equal(skb->dev->dev_addr, rxe_get_av(pkt)->dmac))
 		pkt->mask |= RXE_LOOPBACK_MASK;
diff --git a/roce/rxe/rxe_recv.c b/roce/rxe/rxe_recv.c
index 831ad57..9769203 100644
--- a/roce/rxe/rxe_recv.c
+++ b/roce/rxe/rxe_recv.c
@@ -383,25 +383,27 @@ void rxe_rcv(struct sk_buff *skb)
 	if (unlikely(err))
 		goto drop;
 
-	/* Verify ICRC */
-	icrcp = (__be32 *)(pkt->hdr + pkt->paylen - RXE_ICRC_SIZE);
-	pack_icrc = be32_to_cpu(*icrcp);
-
-	calc_icrc = rxe_icrc_hdr(pkt, skb);
-	calc_icrc = rxe_crc32(rxe, calc_icrc, (u8 *)payload_addr(pkt),
-			      payload_size(pkt) + bth_pad(pkt));
-	calc_icrc = (__force u32)cpu_to_be32(~calc_icrc);
-	if (unlikely(calc_icrc != pack_icrc)) {
-		if (skb->protocol == htons(ETH_P_IPV6))
-			pr_warn_ratelimited("bad ICRC from %pI6c\n",
-					    &ipv6_hdr(skb)->saddr);
-		else if (skb->protocol == htons(ETH_P_IP))
-			pr_warn_ratelimited("bad ICRC from %pI4\n",
-					    &ip_hdr(skb)->saddr);
-		else
-			pr_warn_ratelimited("bad ICRC from unknown\n");
-
-		goto drop;
+	if (!(netif_skb_features(skb) & NETIF_F_ROCEV2_FULL_CRC)) {
+		/* Verify ICRC */
+		icrcp = (__be32 *)(pkt->hdr + pkt->paylen - RXE_ICRC_SIZE);
+		pack_icrc = be32_to_cpu(*icrcp);
+
+		calc_icrc = rxe_icrc_hdr(pkt, skb);
+		calc_icrc = rxe_crc32(rxe, calc_icrc, (u8 *)payload_addr(pkt),
+							  payload_size(pkt) + bth_pad(pkt));
+		calc_icrc = (__force u32)cpu_to_be32(~calc_icrc);
+		if (unlikely(calc_icrc != pack_icrc)) {
+			if (skb->protocol == htons(ETH_P_IPV6))
+				pr_warn_ratelimited("bad ICRC from %pI6c\n",
+									&ipv6_hdr(skb)->saddr);
+			else if (skb->protocol == htons(ETH_P_IP))
+				pr_warn_ratelimited("bad ICRC from %pI4\n",
+									&ip_hdr(skb)->saddr);
+			else
+				pr_warn_ratelimited("bad ICRC from unknown\n");
+
+			goto drop;
+		}
 	}
 
 	rxe_counter_inc(rxe, RXE_CNT_RCVD_PKTS);
diff --git a/roce/rxe/rxe_req.c b/roce/rxe/rxe_req.c
index e503117..01ebdf9 100644
--- a/roce/rxe/rxe_req.c
+++ b/roce/rxe/rxe_req.c
@@ -476,10 +476,10 @@ static int fill_packet(struct rxe_qp *qp, struct rxe_send_wqe *wqe,
 {
 	struct rxe_dev *rxe = to_rdev(qp->ibqp.device);
 	u32 crc = 0;
-	u32 *p;
 	int err;
+	bool hw_crc = netif_skb_features(skb) & NETIF_F_ROCEV2_FULL_CRC;
 
-	err = rxe_prepare(pkt, skb, &crc);
+	err = rxe_prepare(pkt, skb, hw_crc ? NULL : &crc);
 	if (err)
 		return err;
 
@@ -487,7 +487,8 @@ static int fill_packet(struct rxe_qp *qp, struct rxe_send_wqe *wqe,
 		if (wqe->wr.send_flags & IB_SEND_INLINE) {
 			u8 *tmp = &wqe->dma.inline_data[wqe->dma.sge_offset];
 
-			crc = rxe_crc32(rxe, crc, tmp, paylen);
+			if (!hw_crc)
+				crc = rxe_crc32(rxe, crc, tmp, paylen);
 			memcpy(payload_addr(pkt), tmp, paylen);
 
 			wqe->dma.resid -= paylen;
@@ -496,7 +497,7 @@ static int fill_packet(struct rxe_qp *qp, struct rxe_send_wqe *wqe,
 			err = copy_data(qp->pd, 0, &wqe->dma,
 					payload_addr(pkt), paylen,
 					from_mem_obj,
-					&crc);
+					hw_crc ? NULL : &crc);
 			if (err)
 				return err;
 		}
@@ -507,9 +508,20 @@ static int fill_packet(struct rxe_qp *qp, struct rxe_send_wqe *wqe,
 			crc = rxe_crc32(rxe, crc, pad, bth_pad(pkt));
 		}
 	}
-	p = payload_addr(pkt) + paylen + bth_pad(pkt);
 
-	*p = ~crc;
+	if (hw_crc) {
+		skb->ip_summed = CHECKSUM_PARTIAL;
+
+		/* No checksum needed for UDP, but this prevents the
+		 * stack from resetting the transport header pointer.
+		 */
+		skb->csum_start = skb_transport_header(skb) - skb->head;
+	} else {
+		u32 *p;
+
+		p = payload_addr(pkt) + paylen + bth_pad(pkt);
+		*p = ~crc;
+	}
 
 	return 0;
 }
diff --git a/roce/rxe/rxe_resp.c b/roce/rxe/rxe_resp.c
index c4a8195..c08f25d 100644
--- a/roce/rxe/rxe_resp.c
+++ b/roce/rxe/rxe_resp.c
@@ -598,6 +598,7 @@ static struct sk_buff *prepare_ack_packet(struct rxe_qp *qp,
 	int paylen;
 	int pad;
 	int err;
+	bool hw_crc;
 
 	/*
 	 * allocate packet
@@ -609,6 +610,8 @@ static struct sk_buff *prepare_ack_packet(struct rxe_qp *qp,
 	if (!skb)
 		return NULL;
 
+	hw_crc = netif_skb_features(skb) & NETIF_F_ROCEV2_FULL_CRC;
+
 	ack->qp = qp;
 	ack->opcode = opcode;
 	ack->mask = rxe_opcode[opcode].mask;
@@ -634,13 +637,20 @@ static struct sk_buff *prepare_ack_packet(struct rxe_qp *qp,
 	if (ack->mask & RXE_ATMACK_MASK)
 		atmack_set_orig(ack, qp->resp.atomic_orig);
 
-	err = rxe_prepare(ack, skb, &crc);
+	err = rxe_prepare(ack, skb, hw_crc ? NULL : &crc);
 	if (err) {
 		kfree_skb(skb);
 		return NULL;
 	}
 
-	if (crcp) {
+	if (hw_crc) {
+		skb->ip_summed = CHECKSUM_PARTIAL;
+
+		/* No checksum needed for UDP, but this prevents the
+		 * stack from resetting the transport header pointer.
+		 */
+		skb->csum_start = skb_transport_header(skb) - skb->head;
+	} else if (crcp) {
 		/* CRC computation will be continued by the caller */
 		*crcp = crc;
 	} else {
